{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "The notebook presents the execution of KONG for general graphs. All graphs should be downloaded from [here](https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets) as they are stored in a specific format. Please make sure you have downloaded and decompressed the corresponding graph dataset in the folder **general\\_graphs**. Other formats have to be processed such that we obtain the following output:\n",
    "* Vs - list of hashmaps for the nodes, one for each graph. Each hash table maps the node id to its label. For unlabeled graphs this can be set to '1'.\n",
    "* Es - list of hashmaps for the edges, one for each graph. For each node u, we store a list of u's neighbors. (The list is assumed to respect the order of the nodes, if order information is provided.)\n",
    "* classes - a list with the class per graph.\n",
    "* set\\_labels - a set of the labels that appear in all graphs.\n",
    "\n",
    "Before running the code please download 10 files with random numbers from [here](https://web.archive.org/web/20160119150146/http://stat.fsu.edu/pub/diehard/cdrom/) and store them into the folder **random** (if there is no such folder, create it). Also, create the folders **feature maps** and **graphs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import read_write_utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSRC_9\n"
     ]
    }
   ],
   "source": [
    "dirname = 'general_graphs/'\n",
    "filenames = ['MUTAG', 'ENZYMES','PROTEINS', 'NCI1', 'PTC_FM', 'MSRC_9', 'BZR', 'COX2', 'DHFR', 'NCI109']\n",
    "filename = filenames[5]\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general_graphs//MSRC_9/MSRC_9_A.txt\n",
      "222 222\n"
     ]
    }
   ],
   "source": [
    "#read the graphs into the corresponding data structures \n",
    "Vs, Es, classes, set_labels = read_write_utilities.read_standard_graph(dirname, filename)\n",
    "print(len(Vs), len(Es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 3 # the max subtree depth for each node\n",
    "max_p = 2 # the max polynomial degree, here it is only for scalability \n",
    "table_size = 500 # the feature dimensionality for Tensorsketch \n",
    "max_value = 100000 # the total number of features that we will have to sketch\n",
    "nr_tables = 1 # just one table for Tensorsketch, read the original paper for details: http://www.itu.dk/people/pagh/papers/tensorsketch.pdf\n",
    "relabel = False # read the KONG paper for details on relabeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subtree_kernels\n",
    "from count_sketch import CountSketch\n",
    "import tensorsketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count-Sketch data structure initialized\n",
      "Count-Sketch data structure initialized\n"
     ]
    }
   ],
   "source": [
    "random_files = 'random/'\n",
    "cs = CountSketch(table_size, nr_tables*max_p, random_files, max_value)\n",
    "cs_cosine = CountSketch(table_size, nr_tables*max_p, random_files, max_value)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222 222 222\n",
      "100\n",
      "10\n",
      "200\n",
      "10\n",
      "100\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "vectors, vectors_cosine = subtree_kernels.graph2map(Vs, Es, len(classes) + 1, set_labels, h, relabel,  cs, cs_cosine, nr_tables, max_p)\n",
    "WL_feature_maps = subtree_kernels.graph2WLmap(Vs, Es, len(classes) + 1, set_labels, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputpath = 'feature_maps/' + filename + '_'\n",
    "relabeled = ''\n",
    "if relabel:\n",
    "    relabeled = '_relabeled'\n",
    "for k in range(1, h+1):\n",
    "    for p in range(1, max_p+1):\n",
    "        output = outputpath + str(k) + '_' + str(p) + relabeled + '.txt'\n",
    "        output_cosine = outputpath + str(k) + '_' + str(p) + '_cosine' + relabeled + '.txt'\n",
    "           \n",
    "        read_write_utilities.write_vectors_to_file(vectors[(k-1)*max_p + p-1], classes, output)\n",
    "        read_write_utilities.write_vectors_to_file(vectors_cosine[(k-1)*max_p + p-1], classes, output_cosine)\n",
    "output_WL = outputpath + str(k) + '_1_WL.txt'\n",
    "read_write_utilities.write_WL_vectors_to_file(WL_feature_maps, k, classes, output_WL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221, 68)\n"
     ]
    }
   ],
   "source": [
    "#Train Linear SVMs\n",
    "import train_svm\n",
    "p = 2\n",
    "filepath = 'feature_maps/'  + filename + '_' + str(h) + '_' + str(p) + relabeled + '.txt'\n",
    "X_kong, y_kong = train_svm.read_graphs(filepath)\n",
    "X_kong = X_kong.astype(float)\n",
    "print(X_kong.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for KONG\n",
      "0 0.9456521739130433\n",
      "1 0.9545454545454547\n",
      "2 0.9594861660079053\n",
      "3 0.9500000000000002\n",
      "4 0.9547430830039525\n",
      "5 0.95\n",
      "6 0.9545454545454545\n",
      "7 0.9590909090909092\n",
      "8 0.9545454545454547\n",
      "9 0.9454545454545455\n"
     ]
    }
   ],
   "source": [
    "#10-fold accuracy validation\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "print('Results for KONG')\n",
    "nr = 10\n",
    "for i in range(nr):\n",
    "    np.random.seed(i)\n",
    "    perm = np.random.permutation(X_kong.shape[0])\n",
    "    X_kong = X_kong[perm]\n",
    "    y_kong = y_kong[perm]\n",
    "    libsvm_clf = LinearSVC(penalty='l1', C= 1.0, loss='squared_hinge', dual=False, tol=1e-3)\n",
    "    k_fold = KFold(n_splits=10)\n",
    "    print(i, np.mean(cross_val_score(libsvm_clf, X_kong, y_kong, cv=k_fold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221, 12768)\n"
     ]
    }
   ],
   "source": [
    "filepath = 'feature_maps/'  + filename + '_' + str(h) + '_' + str(1)  + '_WL.txt'\n",
    "X_wl, y_wl = train_svm.read_graphs(filepath)\n",
    "X_wl = X_wl.astype(float)\n",
    "print(X_wl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for WL\n",
      "0 0.9183794466403162\n",
      "1 0.900790513833992\n",
      "2 0.9094861660079052\n",
      "3 0.9138339920948617\n",
      "4 0.9181818181818182\n",
      "5 0.9047430830039527\n",
      "6 0.9049407114624506\n",
      "7 0.9136363636363637\n",
      "8 0.9096837944664034\n",
      "9 0.9136363636363637\n"
     ]
    }
   ],
   "source": [
    "print('Results for WL')\n",
    "nr = 10\n",
    "for i in range(nr):\n",
    "    np.random.seed(i)\n",
    "    perm = np.random.permutation(X_wl.shape[0])\n",
    "    X_wl = X_wl[perm]\n",
    "    y_wl = y_wl[perm]\n",
    "    libsvm_clf = LinearSVC(penalty='l1', C= 1.0, loss='squared_hinge', dual=False, tol=1e-3)\n",
    "    k_fold = KFold(n_splits=10)\n",
    "    print(i, np.mean(cross_val_score(libsvm_clf, X_wl, y_wl, cv=k_fold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
